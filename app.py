# app.py
# -*- coding: utf-8 -*-
import json
import time
import re
from typing import Dict, Any, List

import streamlit as st
import google.generativeai as genai

from sheet_review import run_sheet_review

# --------------------------
# 0. Gemini ì„¤ì • (í‚¤ëŠ” secretsì—ì„œë§Œ ì½ê¸°)
# --------------------------
API_KEY = st.secrets.get("GEMINI_API_KEY")
if not API_KEY:
    st.error("GEMINI_API_KEYê°€ secretsì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-2.0-flash-001")


# -------------------------------------------------
# ê³µí†µ ìœ í‹¸
# -------------------------------------------------
def analyze_text_with_gemini(prompt: str, max_retries: int = 5) -> dict:
    """
    ë‹¨ì¼ í…ìŠ¤íŠ¸ ê²€ì‚¬ìš© Gemini í˜¸ì¶œ.
    í•­ìƒ dictë¥¼ ë¦¬í„´í•˜ë„ë¡ ë°©ì–´ ë¡œì§ì„ ë„£ìŒ.
    """
    last_error: Exception | None = None

    for attempt in range(max_retries):
        try:
            generation_config = {
                "response_mime_type": "application/json",
                "temperature": 0.0,
            }
            response = model.generate_content(
                prompt,
                generation_config=generation_config,
            )

            raw = getattr(response, "text", None)
            if raw is None or not str(raw).strip():
                return {
                    "suspicion_score": 5,
                    "content_typo_report": "AI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.",
                    "translated_typo_report": "",
                    "markdown_report": "",
                }

            obj = json.loads(raw)

            if not isinstance(obj, dict):
                return {
                    "suspicion_score": 5,
                    "content_typo_report": f"AI ì‘ë‹µì´ dictê°€ ì•„ë‹˜ (type={type(obj).__name__})",
                    "translated_typo_report": "",
                    "markdown_report": "",
                }

            return obj

        except Exception as e:
            last_error = e
            wait_time = 5 * (attempt + 1)
            print(f"[Gemini(single)] í˜¸ì¶œ ì˜¤ë¥˜ (ì‹œë„ {attempt+1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                print(f"â†’ {wait_time}ì´ˆ í›„ ì¬ì‹œë„")
                time.sleep(wait_time)

    print("[Gemini(single)] ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼.")
    return {
        "suspicion_score": 5,
        "content_typo_report": f"API í˜¸ì¶œ ì‹¤íŒ¨: {last_error}",
        "translated_typo_report": "",
        "markdown_report": "",
    }


def drop_lines_not_in_source(source_text: str, report: str) -> str:
    """
    '- 'ì›ë¬¸' â†’ 'ìˆ˜ì •ì•ˆ': ...' í˜•ì‹ì—ì„œ
    'ì›ë¬¸'ì´ ì‹¤ì œ source_textì— í¬í•¨ë˜ì§€ ì•Šì€ ë¼ì¸ì„ ì œê±°.
    (í•œêµ­ì–´/ì˜ì–´ ê³µí†µ ì‚¬ìš©)
    """
    if not report:
        return ""

    cleaned: List[str] = []
    pattern = re.compile(r"^- '(.+?)' â†’ '(.+?)':", re.UNICODE)

    for line in report.splitlines():
        s = line.strip()
        if not s:
            continue

        m = pattern.match(s)
        if not m:
            cleaned.append(s)
            continue

        original = m.group(1)
        if original in source_text:
            cleaned.append(s)
        else:
            continue

    return "\n".join(cleaned)


def clean_self_equal_corrections(report: str) -> str:
    """
    '- 'ì›ë¬¸' â†’ 'ìˆ˜ì •ì•ˆ': ...' í˜•ì‹ì—ì„œ
    ì›ë¬¸ê³¼ ìˆ˜ì •ì•ˆì´ ì™„ì „íˆ ê°™ì€ ì¤„ì€ ì œê±°í•œë‹¤.
    (ì£¼ë¡œ ì˜ì–´ ìª½ content_typo_reportì— ì‚¬ìš©)
    """
    if not report:
        return ""

    cleaned_lines = []
    pattern = re.compile(r"^- '(.+?)' â†’ '(.+?)':", re.UNICODE)

    for line in report.splitlines():
        line_stripped = line.strip()
        if not line_stripped:
            continue

        m = pattern.match(line_stripped)
        if not m:
            cleaned_lines.append(line_stripped)
            continue

        orig = m.group(1).strip()
        fixed = m.group(2).strip()

        if orig == fixed:
            continue

        cleaned_lines.append(line_stripped)

    return "\n".join(cleaned_lines)


def drop_false_period_errors(english_text: str, report: str) -> str:
    """
    ì˜ì–´ ì›ë¬¸ ëì— ì‹¤ì œë¡œ . ? ! ì´ ìˆìœ¼ë©´
    ë¦¬í¬íŠ¸ì—ì„œ 'ë§ˆì¹¨í‘œ ì—†ìŒ'ë¥˜ ë¬¸ì¥ì„ ì œê±°.
    (ê±°ì§“ ì–‘ì„± ì¤„ì´ê¸°ìš©)
    """
    if not report:
        return ""

    stripped = (english_text or "").rstrip()
    last_char = stripped[-1] if stripped else ""

    if last_char in [".", "?", "!"]:
        bad_phrases = [
            "ë§ˆì¹¨í‘œê°€ ì—†ìŠµë‹ˆë‹¤",
            "ë§ˆì¹¨í‘œê°€ ë¹ ì ¸",
            "ë§ˆì¹¨í‘œê°€ í•„ìš”",
            "ë§ˆì¹¨í‘œë¥¼ ì°ì–´ì•¼",
        ]
        cleaned_lines = []
        for line in report.splitlines():
            if any(p in line for p in bad_phrases):
                continue
            cleaned_lines.append(line.strip())
        return "\n".join(cleaned_lines)

    return report


def drop_false_korean_period_errors(report: str) -> str:
    """
    í•œêµ­ì–´ ë¦¬í¬íŠ¸ì—ì„œ, 'ì›ë¬¸' ë¶€ë¶„ì— ì´ë¯¸ ì¢…ê²°ë¶€í˜¸ê°€ ìˆëŠ”ë°
    'ë§ˆì¹¨í‘œê°€ ì—†ìŠµë‹ˆë‹¤' ë¥˜ë¡œ ì˜ëª» ë³´ê³ í•œ ì¤„ì„ ì œê±°í•œë‹¤.
    """
    if not report:
        return ""

    cleaned_lines = []
    pattern = re.compile(r"^- '(.+?)' â†’ '(.+?)':", re.UNICODE)
    bad_phrases = [
        "ë§ˆì¹¨í‘œê°€ ì—†ìŠµë‹ˆë‹¤",
        "ë§ˆì¹¨í‘œê°€ ë¹ ì ¸",
        "ë§ˆì¹¨í‘œê°€ í•„ìš”",
        "ë§ˆì¹¨í‘œë¥¼ ì°ì–´ì•¼",
        "ë¬¸ì¥ ëì— ë§ˆì¹¨í‘œê°€ ì—†",
    ]

    for line in report.splitlines():
        s = line.strip()
        if not s:
            continue

        if not any(p in s for p in bad_phrases):
            cleaned_lines.append(s)
            continue

        m = pattern.match(s)
        if not m:
            cleaned_lines.append(s)
            continue

        original = m.group(1).rstrip()
        if not original:
            cleaned_lines.append(s)
            continue

        last = original[-1]
        ok = False
        if last in ".?!":
            ok = True
        elif len(original) >= 2 and last in ['"', "'", "â€", "â€™", "ã€", "ã€", "ã€‹", "ã€‰", ")", "]"] and original[-2] in ".?!":
            ok = True

        if ok:
            # ì´ë¯¸ ì¢…ê²°ë¶€í˜¸ê°€ ìˆëŠ” ë¬¸ì¥ì¸ë° 'ë§ˆì¹¨í‘œ ì—†ìŒ'ì´ë¼ê³  í•œ ì¤„ â†’ ë²„ë¦¼
            continue
        else:
            cleaned_lines.append(s)

    return "\n".join(cleaned_lines)


def ensure_final_punctuation_error(text: str, report: str) -> str:
    """
    ë¬¸ë‹¨ ë§ˆì§€ë§‰ ë¬¸ì¥ì˜ ëì— ì¢…ê²°ë¶€í˜¸(. ? !)ê°€ ì—†ìœ¼ë©´
    reportì— ì˜¤ë¥˜ë¥¼ ê°•ì œë¡œ í•œ ì¤„ ì¶”ê°€í•œë‹¤.
    """
    if not text or not text.strip():
        return report or ""

    s = text.rstrip()
    if not s:
        return report or ""

    last = s[-1]
    end_ok = False
    if last in ".?!":
        end_ok = True
    elif last in ['"', "'", "â€", "â€™", "ã€", "ã€", "ã€‹", "ã€‰", ")", "]"] and len(s) >= 2 and s[-2] in ".?!":
        end_ok = True

    if end_ok:
        return report or ""

    # ì´ë¯¸ ë¹„ìŠ·í•œ ë©˜íŠ¸ê°€ ìˆìœ¼ë©´ ì¤‘ë³µ ì¶”ê°€ ì•ˆ í•¨
    if report and ("ë§ˆì§€ë§‰ ë¬¸ì¥ì— ë§ˆì¹¨í‘œ" in report or "ë¬¸ì¥ ëì— ë§ˆì¹¨í‘œê°€ ì—†" in report):
        return report

    line = "- 'ìˆ˜ ìˆì—ˆë‹¤' â†’ 'ìˆ˜ ìˆì—ˆë‹¤.': ë§ˆì§€ë§‰ ë¬¸ì¥ì— ë§ˆì¹¨í‘œê°€ ì—†ìŠµë‹ˆë‹¤."
    # ìœ„ ì˜ˆì‹œëŠ” ì‹¤ì œ ì›ë¬¸ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ê°€ì§€ëŠ” ì•Šì§€ë§Œ, ìš”ì•½í˜• í•œ ì¤„ë¡œ ì‚¬ìš©
    if report:
        return report.rstrip() + "\n" + line
    else:
        return line


def ensure_sentence_end_punctuation(text: str, report: str) -> str:
    """
    ë¬¸ë‹¨ ë‚´ ëª¨ë“  ë¬¸ì¥ì˜ ëì— ì¢…ê²°ë¶€í˜¸(. ? !)ê°€ ìˆëŠ”ì§€ ëŒ€ëµ ê²€ì‚¬.
    ëˆ„ë½ëœ ë¬¸ì¥ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ìš”ì•½ ë©”ì‹œì§€ë¥¼ ì¶”ê°€.
    ë‹¤ë§Œ ì´ë¯¸ ë‹¤ë¥¸ ì¤„ì—ì„œ ì¢…ê²°ë¶€í˜¸ ëˆ„ë½ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í–ˆë‹¤ë©´
    ì¤‘ë³µ ë©”ì‹œì§€ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.
    """
    if not text or not text.strip():
        return report or ""

    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    missing = []

    for s in sentences:
        s = s.strip()
        if not s:
            continue

        ok = False
        if s[-1] in ".?!":
            ok = True
        elif len(s) >= 2 and s[-1] in ['"', "'", "â€", "â€™", "ã€", "ã€", "ã€‹", "ã€‰", ")", "]"] and s[-2] in ".?!":
            ok = True

        if not ok:
            missing.append(s)

    if not missing:
        return report or ""

    # ì´ë¯¸ ì¢…ê²°ë¶€í˜¸ ê´€ë ¨ ë©˜íŠ¸ê°€ ìˆìœ¼ë©´ ìš”ì•½ ì¤„ ìƒëµ
    if report and any(
        key in report
        for key in ["ë§ˆì§€ë§‰ ë¬¸ì¥ì— ë§ˆì¹¨í‘œ", "ì¢…ê²°ë¶€í˜¸", "ë¬¸ì¥ ëì— ë§ˆì¹¨í‘œê°€ ì—†", "ë§ˆì¹¨í‘œê°€ ì—†ìŠµë‹ˆë‹¤"]
    ):
        return report

    line = "- ë¬¸ì¥ ëì— ì¢…ê²°ë¶€í˜¸(., ?, !)ê°€ ëˆ„ë½ëœ ë¬¸ì¥ì´ ìˆìŠµë‹ˆë‹¤."

    if report:
        return report.rstrip() + "\n" + line
    else:
        return line


def dedup_korean_bullet_lines(report: str) -> str:
    """
    í•œêµ­ì–´ bullet ë¦¬í¬íŠ¸ì—ì„œ ì˜ë¯¸ê°€ ê²¹ì¹˜ëŠ” ì¤„ì„ ì •ë¦¬í•œë‹¤.
    - ì™„ì „íˆ ë™ì¼í•œ ì¤„ì€ í•˜ë‚˜ë§Œ ë‚¨ê¹€
    - 'ë¶ˆí•„ìš”í•œ ë§ˆì¹¨í‘œ'ë¥˜ì—ì„œ ì›ë¬¸ì´ ë¶€ë¶„ ë¬¸ìì—´ ê´€ê³„ì´ë©´ ë” ê¸´ ìª½ë§Œ ìœ ì§€
    """
    if not report:
        return ""

    lines = [l.strip() for l in report.splitlines() if l.strip()]
    if not lines:
        return ""

    pattern = re.compile(r"^- '(.+?)' â†’ '(.+?)':\s*(.+)$", re.UNICODE)

    # 1ì°¨: ì™„ì „ ì¤‘ë³µ ì œê±°
    unique_lines = []
    seen = set()
    for l in lines:
        if l not in seen:
            unique_lines.append(l)
            seen.add(l)

    entries = []
    for idx, l in enumerate(unique_lines):
        m = pattern.match(l)
        if not m:
            entries.append({"idx": idx, "raw": l, "orig": None, "msg": ""})
            continue
        orig, fixed, msg = m.group(1), m.group(2), m.group(3)
        entries.append({"idx": idx, "raw": l, "orig": orig, "msg": msg})

    to_drop = set()
    for i, e1 in enumerate(entries):
        if not e1["orig"] or "ë¶ˆí•„ìš”í•œ ë§ˆì¹¨í‘œ" not in e1["msg"]:
            continue
        for j, e2 in enumerate(entries):
            if i == j or not e2["orig"] or "ë¶ˆí•„ìš”í•œ ë§ˆì¹¨í‘œ" not in e2["msg"]:
                continue
            o1, o2 = e1["orig"], e2["orig"]
            if o1 in o2 and len(o1) < len(o2):
                to_drop.add(e1["idx"])
            elif o2 in o1 and len(o2) < len(o1):
                to_drop.add(e2["idx"])

    final_lines = [
        l for idx, l in enumerate(unique_lines) if idx not in to_drop
    ]

    return "\n".join(final_lines)


def validate_and_clean_analysis(result: dict, original_english_text: str | None = None) -> dict:
    """
    AI ì‘ë‹µì—ì„œ ë¬¸ì²´ ì œì•ˆ ë“±ì„ í•„í„°ë§í•˜ê³  ì ìˆ˜ë¥¼ ë³´ì • + (ì˜ì–´ ìª½ ì¶”ê°€ í›„ì²˜ë¦¬)
    """
    if not isinstance(result, dict):
        return {
            "suspicion_score": 5,
            "content_typo_report": "AI ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹˜",
            "translated_typo_report": "",
            "markdown_report": "",
        }

    score = result.get("suspicion_score")
    reports = {
        "content_typo_report": result.get("content_typo_report", "") or "",
        "translated_typo_report": result.get("translated_typo_report", "") or "",
        "markdown_report": result.get("markdown_report", "") or "",
    }

    # ìŠ¤íƒ€ì¼/ë¬¸ì²´ ì œì•ˆ ê¸ˆì§€ í‚¤ì›Œë“œ í•„í„°
    forbidden_keywords = [
        "ë¬¸ë§¥ìƒ",
        "ë¶€ì ì ˆ",
        "ì–´ìƒ‰",
        "ë” ìì—°ìŠ¤ëŸ½",
        "ë” ì ì ˆ",
        "ìˆ˜ì •í•˜ëŠ” ê²ƒì´ ì¢‹",
        "ì œì•ˆ",
        "ë°”ê¾¸ëŠ” ê²ƒ",
        "ì˜ë¯¸ë¥¼ ëª…í™•íˆ",
    ]
    for key, text in reports.items():
        if any(kw in text for kw in forbidden_keywords):
            reports[key] = ""

    # "ì˜¤ë¥˜ ì—†ìŒ"ë¥˜ ë©˜íŠ¸ ì œê±°
    forbidden_phrases = ["ì˜¤ë¥˜ ì—†ìŒ", "ì •ìƒ", "ë¬¸ì œ ì—†ìŒ", "ìˆ˜ì •í•  í•„ìš” ì—†ìŒ"]
    for key, text in reports.items():
        if any(ph in text for ph in forbidden_phrases):
            reports[key] = ""

    # ì˜ì–´ ë¦¬í¬íŠ¸ í›„ì²˜ë¦¬
    english_report = reports["content_typo_report"]
    english_report = clean_self_equal_corrections(english_report)
    if original_english_text:
        english_report = drop_false_period_errors(original_english_text, english_report)
    reports["content_typo_report"] = english_report

    final_content = reports["content_typo_report"]
    final_translated = reports["translated_typo_report"]
    final_markdown = reports["markdown_report"]

    # score ê¸°ë³¸ê°’ ë³´ì •
    try:
        score = int(score)
    except Exception:
        score = 1

    if score < 1:
        score = 1
    if score > 5:
        score = 5

    if not final_content and not final_translated and not final_markdown:
        score = 1
    elif (final_content or final_translated or final_markdown) and score == 1:
        score = 3

    return {
        "suspicion_score": score,
        "content_typo_report": final_content,
        "translated_typo_report": final_translated,
        "markdown_report": final_markdown,
    }


# -------------------------------------------------
# 1-A. í•œêµ­ì–´ ë‹¨ì¼ í…ìŠ¤íŠ¸ ê²€ìˆ˜ í”„ë¡¬í”„íŠ¸ + ë˜í¼
# -------------------------------------------------
def create_korean_review_prompt_for_text(korean_text: str) -> str:
    prompt = f"""
ë‹¹ì‹ ì€ ê¸°ê³„ì ìœ¼ë¡œ ë™ì‘í•˜ëŠ” **Korean text proofreader**ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ **ê°ê´€ì ì´ê³  ê²€ì¦ ê°€ëŠ¥í•œ ì˜¤ë¥˜ë§Œ** ì°¾ì•„ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤.
ìŠ¤íƒ€ì¼, ì–´íˆ¬, ìì—°ìŠ¤ëŸ¬ì›€, í‘œí˜„ ê°œì„ , ì˜ë„ ì¶”ë¡ ê³¼ ê°™ì€ ì£¼ê´€ì  íŒë‹¨ì€ ì ˆëŒ€ í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ 4ê°œì˜ keyë§Œ í¬í•¨í•˜ëŠ” **ë‹¨ì¼ JSON ê°ì²´**ì—¬ì•¼ í•©ë‹ˆë‹¤.
- "suspicion_score": 1~5 ì •ìˆ˜
- "content_typo_report": "" (ë¹„ì›Œë‘ê¸° â€” ì˜ì–´ìš© í•„ë“œ)
- "translated_typo_report": í•œêµ­ì–´ ì˜¤ë¥˜ ì„¤ëª… (ì—†ìœ¼ë©´ "")
- "markdown_report": "" (í•­ìƒ ë¹ˆ ë¬¸ìì—´)

ëª¨ë“  ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œêµ­ì–´ë¡œ** ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
ì˜¤ë¥˜ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ëª¨ë“  report í•„ë“œëŠ” "" ì—¬ì•¼ í•©ë‹ˆë‹¤.

------------------------------------------------------------
# ğŸš¨ ì ˆëŒ€ ê¸ˆì§€ ê·œì¹™ (Hallucination ë°©ì§€ â€” ë§¤ìš° ì¤‘ìš”)
------------------------------------------------------------
âŒ ì…ë ¥ í…ìŠ¤íŠ¸ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´Â·êµ¬ì ˆì„ ìƒì„±  
âŒ ì˜ë„Â·ê°ì •Â·ë‚´ìš©ì„ ì¶”ë¡ í•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì¥ì„ ì œì•ˆ  
âŒ ë¬¸ì¥ì„ ë°”ê¾¸ê±°ë‚˜ ë‹¤ë¥¸ ë§ë¡œ ë°”ê¿” í‘œí˜„  
âŒ ì…ë ¥ë˜ì§€ ì•Šì€ ë‹¨ì–´ë¥¼ ìˆ˜ì • ëŒ€ìƒìœ¼ë¡œ ì§€ëª©  
âŒ ë‚´ìš© ì™œê³¡ ë˜ëŠ” ì˜ë¯¸ì  ë¹„í‰

ì˜¤ì§ â€œì…ë ¥ ë¬¸ìì—´ ì•ˆì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” í† í°â€ë§Œ ì¸ìš©í•˜ê³  ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.

ë˜í•œ, "- 'ì›ë¬¸' â†’ 'ìˆ˜ì •ì•ˆ': ..." í˜•ì‹ì—ì„œ 'ì›ë¬¸' ë¶€ë¶„ì€
ë°˜ë“œì‹œ plain_korean ì•ˆì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë¶€ë¶„ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

------------------------------------------------------------
# 1. í•œêµ­ì–´ì—ì„œ ë°˜ë“œì‹œ ì¡ì•„ì•¼ í•˜ëŠ” ê°ê´€ì  ì˜¤ë¥˜
------------------------------------------------------------

(ì¤‘ëµ â€“ sheet í”„ë¡¬í”„íŠ¸ì™€ ë™ì¼ ê·œì¹™)

------------------------------------------------------------
# 3. ê²€ì‚¬í•  í…ìŠ¤íŠ¸
------------------------------------------------------------

plain_korean: "{korean_text}"

ì´ì œ ìœ„ ê·œì¹™ì„ ì§€í‚¤ë©° ìœ„ì˜ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ê²€ìˆ˜í•˜ì„¸ìš”.
"""
    return prompt


def review_korean_text(korean_text: str) -> Dict[str, Any]:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê²€ìˆ˜ ë˜í¼"""
    prompt = create_korean_review_prompt_for_text(korean_text)
    raw = analyze_text_with_gemini(prompt)
    cleaned = validate_and_clean_analysis(raw)

    filtered = drop_lines_not_in_source(
        korean_text,
        cleaned.get("translated_typo_report", "") or "",
    )
    filtered = drop_false_korean_period_errors(filtered)
    filtered = ensure_final_punctuation_error(korean_text, filtered)
    filtered = ensure_sentence_end_punctuation(korean_text, filtered)
    filtered = dedup_korean_bullet_lines(filtered)

    return {
        "score": cleaned.get("suspicion_score"),
        "content_typo_report": cleaned.get("content_typo_report", ""),
        "translated_typo_report": filtered,
        "markdown_report": cleaned.get("markdown_report", ""),
        "raw": raw,
    }


# -------------------------------------------------
# 1-B. ì˜ì–´ ë‹¨ì¼ í…ìŠ¤íŠ¸ ê²€ìˆ˜ í”„ë¡¬í”„íŠ¸ + ë˜í¼
# -------------------------------------------------
def create_english_review_prompt_for_text(english_text: str) -> str:
    prompt = f"""
You are a machine-like **English text proofreader**.
Your ONLY job is to detect **objective, verifiable errors** in the following English text.
You are strictly forbidden from judging tone, style, naturalness, or suggesting alternative phrasing.

Your response MUST be a valid JSON object with exactly these keys:
- "suspicion_score": integer (1~5)
- "content_typo_report": string
- "translated_typo_report": string
- "markdown_report": string

All explanations in the *_report fields MUST be written in **Korean**.
If nothing is wrong, each report field MUST be an empty string "".

(ì¤‘ëµ â€“ ì‹œíŠ¸ ì˜ì–´ í”„ë¡¬í”„íŠ¸ì™€ ë™ì¼ ê·œì¹™)

plain_english: "{english_text}"
"""
    return prompt


def review_english_text(english_text: str) -> Dict[str, Any]:
    """ì˜ì–´ í…ìŠ¤íŠ¸ ê²€ìˆ˜ ë˜í¼"""
    prompt = create_english_review_prompt_for_text(english_text)
    raw = analyze_text_with_gemini(prompt)
    cleaned = validate_and_clean_analysis(raw, original_english_text=english_text)
    return {
        "score": cleaned.get("suspicion_score"),
        "content_typo_report": cleaned.get("content_typo_report", ""),
        "raw": raw,
    }


# -------------------------------------------------
# ê³µí†µ: JSON diff / ì œì•ˆ ì¶”ì¶œ
# -------------------------------------------------
def summarize_json_diff(raw: dict | None, final: dict | None) -> str:
    if not isinstance(raw, dict):
        raw = {}
    if not isinstance(final, dict):
        final = {}

    lines = []
    all_keys = sorted(set(raw.keys()) | set(final.keys()))

    for key in all_keys:
        rv = raw.get(key, "<ì—†ìŒ>")
        fv = final.get(key, "<ì—†ìŒ>")
        if rv == fv:
            continue

        rv_str = json.dumps(rv, ensure_ascii=False) if isinstance(rv, (dict, list)) else str(rv)
        fv_str = json.dumps(fv, ensure_ascii=False) if isinstance(fv, (dict, list)) else str(fv)

        lines.append(
            f"- **{key}**\n"
            f"  - raw: `{rv_str}`\n"
            f"  - final: `{fv_str}`"
        )

    if not lines:
        return "ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤. (rawì™€ finalì´ ë™ì¼í•©ë‹ˆë‹¤.)"

    return "\n".join(lines)


def extract_korean_suggestions_from_raw(raw: dict) -> list[str]:
    if not isinstance(raw, dict):
        return []
    collected = []
    fields = [
        raw.get("translated_typo_report", ""),
        raw.get("content_typo_report", ""),
        raw.get("markdown_report", ""),
    ]
    for block in fields:
        if not block:
            continue
        for line in block.split("\n"):
            line = line.strip()
            if not line:
                continue
            if not line.startswith("- "):
                line = f"- {line}"
            collected.append(line)
    return collected


def extract_english_suggestions_from_raw(raw: dict) -> list[str]:
    if not isinstance(raw, dict):
        return []
    collected: list[str] = []
    fields = [
        raw.get("content_typo_report", ""),
        raw.get("translated_typo_report", ""),
        raw.get("markdown_report", ""),
    ]
    for block in fields:
        if not block:
            continue
        for line in block.split("\n"):
            line = line.strip()
            if not line:
                continue
            if not line.startswith("- "):
                line = f"- {line}"
            collected.append(line)
    return collected


# -------------------------------------------------
# 2. Streamlit UI
# -------------------------------------------------
st.set_page_config(
    page_title="AI ê²€ìˆ˜ê¸° (Gemini)",
    page_icon="ğŸ“š",
    layout="wide",
)

st.title("ğŸ“š AI í…ìŠ¤íŠ¸ ê²€ìˆ˜ê¸° (Gemini ê¸°ë°˜)")
st.caption("í•œêµ­ì–´/ì˜ì–´ ë‹¨ì¼ í…ìŠ¤íŠ¸ + Google Sheets ê¸°ë°˜ ê²€ìˆ˜ê¸° (ì˜¤íƒˆì/í˜•ì‹ ìœ„ì£¼, ìŠ¤íƒ€ì¼ ì œì•ˆ ê¸ˆì§€).")

tab_ko, tab_en, tab_sheet, tab_about, tab_debug = st.tabs(
    ["âœï¸ í•œêµ­ì–´ ê²€ìˆ˜", "âœï¸ ì˜ì–´ ê²€ìˆ˜", "ğŸ“„ ì‹œíŠ¸ ê²€ìˆ˜", "â„¹ï¸ ì„¤ëª…", "ğŸ ë””ë²„ê·¸"]
)

# --- í•œêµ­ì–´ ê²€ìˆ˜ íƒ­ ---
with tab_ko:
    st.subheader("í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê²€ìˆ˜")
    default_ko = "ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ì…ë‹ˆë‹¤, ê·¸ëŠ”.ëŠ” í•™êµì— ê°”ë‹¤,"
    text_ko = st.text_area(
        "í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì…ë ¥",
        value=default_ko,
        height=220,
    )

    if st.button("í•œêµ­ì–´ ê²€ìˆ˜ ì‹¤í–‰", type="primary"):
        if not text_ko.strip():
            st.warning("ë¨¼ì € í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ê²€ìˆ˜ ì¤‘ì…ë‹ˆë‹¤..."):
                result = review_korean_text(text_ko)
            st.session_state["ko_result"] = result

    if "ko_result" in st.session_state:
        result = st.session_state["ko_result"]
        score = result.get("score", 1)
        raw_json = result.get("raw", {}) or {}

        final_json = {
            "suspicion_score": result.get("score", 1),
            "translated_typo_report": result.get("translated_typo_report", ""),
        }

        raw_view = {
            "suspicion_score": raw_json.get("suspicion_score"),
            "translated_typo_report": raw_json.get("translated_typo_report", ""),
        }

        st.success("í•œêµ­ì–´ ê²€ìˆ˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.metric("ì˜ì‹¬ ì ìˆ˜ (1~5)", f"{float(score):.2f}")

        st.markdown("### ğŸ” ê²°ê³¼ ë¹„êµ (Raw vs Final)")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### âœ… Final JSON (í›„ì²˜ë¦¬ ì ìš©)")
            st.json(final_json, expanded=False)
        with col2:
            st.markdown("#### ğŸ§ª Raw JSON (ë™ì¼ í•„ë“œë§Œ ë°œì·Œ)")
            st.json(raw_view, expanded=False)

        st.markdown("#### ğŸ” Raw vs Final ì°¨ì´ ìš”ì•½")
        diff_md = summarize_json_diff(raw_view, final_json)
        st.markdown(diff_md)

        st.markdown("### ğŸ›  ìµœì¢… ìˆ˜ì • ì œì•ˆ ì‚¬í•­")
        suggestions = extract_korean_suggestions_from_raw({"translated_typo_report": final_json["translated_typo_report"]})
        if not suggestions:
            st.info("ë³´ê³ í•  ìˆ˜ì • ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for s in suggestions:
                st.markdown(s)


# --- ì˜ì–´ ê²€ìˆ˜ íƒ­ ---
with tab_en:
    st.subheader("ì˜ì–´ í…ìŠ¤íŠ¸ ê²€ìˆ˜")
    default_en = 'This is a simple understaning of the Al model.'
    text_en = st.text_area(
        "English text input",
        value=default_en,
        height=220,
    )

    if st.button("ì˜ì–´ ê²€ìˆ˜ ì‹¤í–‰", type="primary"):
        if not text_en.strip():
            st.warning("ë¨¼ì € ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ê²€ìˆ˜ ì¤‘ì…ë‹ˆë‹¤..."):
                result = review_english_text(text_en)
            st.session_state["en_result"] = result

    if "en_result" in st.session_state:
        result = st.session_state["en_result"]
        score = result.get("score", 1)
        raw_json = result.get("raw", {}) or {}

        final_json = {
            "suspicion_score": result.get("score", 1),
            "content_typo_report": result.get("content_typo_report", ""),
        }

        raw_view = {
            "suspicion_score": raw_json.get("suspicion_score"),
            "content_typo_report": raw_json.get("content_typo_report", ""),
        }

        st.success("ì˜ì–´ ê²€ìˆ˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.metric("Suspicion score (1~5)", f"{float(score):.2f}")

        st.markdown("### ğŸ” ê²°ê³¼ ë¹„êµ (Raw vs Final)")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### âœ… Final JSON (í›„ì²˜ë¦¬ ì ìš©)")
            st.json(final_json, expanded=False)
        with col2:
            st.markdown("#### ğŸ§ª Raw JSON (ë™ì¼ í•„ë“œë§Œ ë°œì·Œ)")
            st.json(raw_view, expanded=False)

        st.markdown("#### ğŸ” Raw vs Final ì°¨ì´ ìš”ì•½")
        diff_md = summarize_json_diff(raw_view, final_json)
        st.markdown(diff_md)

        st.markdown("### ğŸ›  ìµœì¢… ìˆ˜ì • ì œì•ˆ ì‚¬í•­ (ì˜ì–´ ì›ë¬¸ ê¸°ì¤€)")
        suggestions = extract_english_suggestions_from_raw(raw_json)
        if not suggestions:
            st.info("ë³´ê³ í•  ìˆ˜ì • ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for s in suggestions:
                st.markdown(s)


# --- ì‹œíŠ¸ ê²€ìˆ˜ íƒ­ ---
with tab_sheet:
    st.subheader("ğŸ“„ Google Sheets ì‹œíŠ¸ ê²€ìˆ˜")

    # ğŸ”½ í•˜ë“œì½”ë”©ëœ ë“œë¡­ë‹¤ìš´ ëª©ë¡
    sheet_options = [
        "[DATA] Paragraph DB (êµê³¼ì„œ)",
        "[DATA] Paragraph DB (ì°¸ê³ ì„œ)",
        "[DATA] Paragraph DB (ëª¨ì˜ê³ ì‚¬)",
    ]

    worksheet_options = [
        "ìµœì¢…ë°ì´í„°",
        "22ê°œì •",
    ]

    # ğŸ”½ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
    spreadsheet_name = st.selectbox(
        "ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì„ íƒ",
        options=sheet_options,
    )

    # ğŸ”½ ì›Œí¬ì‹œíŠ¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
    worksheet_name = st.selectbox(
        "ì›Œí¬ì‹œíŠ¸ ì„ íƒ",
        options=worksheet_options,
    )

    col_btn, col_blank = st.columns([1, 4])
    with col_btn:
        run_clicked = st.button("ì´ ì‹œíŠ¸ ê²€ìˆ˜ ì‹¤í–‰", type="primary")

    if run_clicked:
        if not spreadsheet_name or not worksheet_name:
            st.warning("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì™€ ì›Œí¬ì‹œíŠ¸ë¥¼ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            progress_bar = st.progress(0.0)
            progress_text = st.empty()

            with st.spinner("ì‹œíŠ¸ ê²€ìˆ˜ ì¤‘ì…ë‹ˆë‹¤... (í–‰ì´ ë§ìœ¼ë©´ ì‹œê°„ì´ ê±¸ë ¤ìš”)"):
                try:
                    summary = run_sheet_review(
                        spreadsheet_name,
                        worksheet_name,
                        collect_raw=True,
                        progress_callback=lambda done, total: (
                            progress_bar.progress(done / total),
                            progress_text.text(f"ì§„í–‰ë„: {done}/{total} ì™„ë£Œ")
                        ),
                    )
                except Exception as e:
                    st.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                else:
                    progress_bar.progress(1.0)
                    st.success("ê²€ìˆ˜ ì™„ë£Œ!")
                    st.session_state["sheet_summary"] = summary
                    st.session_state["raw_results"] = summary.get("raw_results", [])
                    st.rerun()


    summary = st.session_state.get("sheet_summary")
    raw_results = st.session_state.get("raw_results", [])

    if summary:
        st.divider()
        total_rows = summary.get("total_rows", 0)
        target_rows = summary.get("target_rows", 0)
        processed_rows = summary.get("processed_rows", 0)
        remaining_rows = max(target_rows - processed_rows, 0)

        st.success("âœ… ì‹œíŠ¸ ê²€ìˆ˜ ì‘ì—… ì™„ë£Œ (ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤)")
        col_m1, col_m2, col_m3, col_m4 = st.columns(4)
        with col_m1:
            st.metric("ì „ì²´ í–‰ ìˆ˜", total_rows)
        with col_m2:
            st.metric("ê²€ìˆ˜ ëŒ€ìƒ í–‰ ìˆ˜", target_rows)
        with col_m3:
            st.metric("ì‹¤ì œ ì²˜ë¦¬ëœ í–‰ ìˆ˜", processed_rows)
        with col_m4:
            st.metric("ë‚¨ì€ ëŒ€ìƒ í–‰", remaining_rows)

        st.info("ğŸ‘‰ Google Sheetsì—ì„œ SCORE / *_REPORT / STATUS ì»¬ëŸ¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        st.markdown("### ğŸ ë””ë²„ê·¸: íŠ¹ì • í–‰ì˜ Raw / Final JSON & Diff")

        if not raw_results:
            st.info("ìˆ˜ì§‘ëœ Raw ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê²€ìˆ˜ ëŒ€ìƒ í–‰ì´ ì—†ì—ˆê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ)")
        else:
            row_numbers = [item["sheet_row_index"] for item in raw_results]

            selected_candidate = st.selectbox(
                "Raw/Final JSONì„ ë³´ê³  ì‹¶ì€ í–‰ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                options=row_numbers,
                format_func=lambda x: f"í–‰ {x}ë²ˆ",
            )

            if st.button("ì„ íƒí•œ í–‰ ë¶„ì„ ë³´ê¸°"):
                st.session_state["selected_row"] = selected_candidate

            selected_row = st.session_state.get("selected_row")

            if selected_row is not None:
                selected_item = next(
                    (item for item in raw_results if item["sheet_row_index"] == selected_row),
                    None,
                )

                if selected_item:
                    st.markdown(f"#### ğŸ” í–‰ {selected_row}ë²ˆ ë¶„ì„ ê²°ê³¼")

                    view_mode = st.radio(
                        "ì–´ëŠ ìª½ ê²°ê³¼ë¥¼ ë³¼ê¹Œìš”?",
                        [
                            "í†µí•© ê²°ê³¼ (ì‹œíŠ¸ ê¸°ë¡ê°’)",
                            "ì˜ì–´ ì›ë¬¸ ì „ìš© (content)",
                            "í•œêµ­ì–´ ë²ˆì—­ ì „ìš© (content_translated)",
                            "ë§ˆí¬ë‹¤ìš´ ê´€ë ¨ ì˜¤ë¥˜ (content_markdown + content_markdown_translated)",
                        ],
                        horizontal=True,
                    )

                    # 1) í†µí•© ê²°ê³¼: ì‹œíŠ¸ì— ì‹¤ì œë¡œ ì íŒ combined_final ê·¸ëŒ€ë¡œ
                    if view_mode.startswith("í†µí•©"):
                        st.markdown("##### ğŸ§¾ ì‹œíŠ¸ì— ê¸°ë¡ëœ í†µí•© ê²°ê³¼ (combined_final)")
                        st.json(selected_item.get("combined_final", {}))

                    # 2) ì˜ì–´ ì›ë¬¸ ì „ìš© ë””ë²„ê·¸
                    elif view_mode.startswith("ì˜ì–´"):
                        bundle = selected_item.get("english", {}) or {}
                        raw_json = bundle.get("raw") or {}
                        final_json = bundle.get("final") or {}

                        st.markdown("##### ğŸ“„ ì˜ì–´ ì›ë¬¸ í…ìŠ¤íŠ¸ (plain)")
                        st.code(bundle.get("text_plain", "") or "", language="markdown")

                        st.markdown("##### ğŸ“ ì˜ì–´ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ (content_markdown)")
                        st.code(bundle.get("text_markdown", "") or "", language="markdown")

                        st.markdown("##### âš¡ Raw vs Final ì°¨ì´ì  (í•„í„°ë§ í™•ì¸)")
                        diff_md = summarize_json_diff(raw_json, final_json)
                        st.markdown(diff_md)

                        st.divider()
                        col_final, col_raw = st.columns(2)
                        with col_raw:
                            st.markdown("##### ğŸ¤– Raw JSON (AI ì›ë³¸)")
                            st.json(raw_json)
                        with col_final:
                            st.markdown("##### ğŸ§¹ Final JSON (í›„ì²˜ë¦¬ ì ìš©)")
                            st.json(final_json)

                    # 3) í•œêµ­ì–´ ë²ˆì—­ ì „ìš© ë””ë²„ê·¸
                    elif view_mode.startswith("í•œêµ­ì–´"):
                        bundle = selected_item.get("korean", {}) or {}
                        raw_json = bundle.get("raw") or {}
                        final_json = bundle.get("final") or {}

                        st.markdown("##### ğŸ“„ í•œêµ­ì–´ ë²ˆì—­ í…ìŠ¤íŠ¸ (plain)")
                        st.code(bundle.get("text_plain", "") or "", language="markdown")

                        st.markdown("##### ğŸ“ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ (content_markdown_translated)")
                        st.code(bundle.get("text_markdown", "") or "", language="markdown")

                        st.markdown("##### âš¡ Raw vs Final ì°¨ì´ì  (í•„í„°ë§ í™•ì¸)")
                        diff_md = summarize_json_diff(raw_json, final_json)
                        st.markdown(diff_md)

                        st.divider()
                        col_final, col_raw = st.columns(2)
                        with col_raw:
                            st.markdown("##### ğŸ¤– Raw JSON (AI ì›ë³¸)")
                            st.json(raw_json)
                        with col_final:
                            st.markdown("##### ğŸ§¹ Final JSON (í›„ì²˜ë¦¬ ì ìš©)")
                            st.json(final_json)

                    # 4) ë§ˆí¬ë‹¤ìš´ ê´€ë ¨ ì˜¤ë¥˜ë§Œ ëª¨ì•„ì„œ ë³´ê¸°
                    else:
                        combined_final = selected_item.get("combined_final", {}) or {}
                        markdown_report = combined_final.get("markdown_report", "") or ""

                        en_md = (selected_item.get("english", {}) or {}).get("text_markdown", "") or ""
                        ko_md = (selected_item.get("korean", {}) or {}).get("text_markdown", "") or ""

                        st.markdown("##### ğŸ“„ ì˜ì–´ ë§ˆí¬ë‹¤ìš´ ì›ë¬¸ (content_markdown)")
                        if en_md.strip():
                            st.code(en_md, language="markdown")
                        else:
                            st.info("ì˜ì–´ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

                        st.markdown("##### ğŸ“„ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ ì›ë¬¸ (content_markdown_translated)")
                        if ko_md.strip():
                            st.code(ko_md, language="markdown")
                        else:
                            st.info("í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

                        st.markdown("##### ğŸ§· MARKDOWN_REPORT (ë‘ ì–¸ì–´ ë§ˆí¬ë‹¤ìš´ ì˜¤ë¥˜ í†µí•©)")
                        if markdown_report.strip():
                            st.markdown(markdown_report)
                        else:
                            st.info("ë§ˆí¬ë‹¤ìš´ ê´€ë ¨ìœ¼ë¡œ ë³´ê³ ëœ ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ì„ íƒí•œ í–‰ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")



# --- ì„¤ëª… íƒ­ ---
with tab_about:
    st.markdown("""
## ì´ ì•±ì€?

- í•œêµ­ì–´/ì˜ì–´ **ë‹¨ì¼ í…ìŠ¤íŠ¸ ê²€ìˆ˜ê¸°** + **Google Sheets ê¸°ë°˜ ë°°ì¹˜ ê²€ìˆ˜ê¸°**ì…ë‹ˆë‹¤.
- ìŠ¤íƒ€ì¼/ì–´íˆ¬/ìì—°ìŠ¤ëŸ¬ì›€ì€ ê±´ë“œë¦¬ì§€ ì•Šê³ , **ì˜¤íƒˆì / ì¡°ì‚¬ / ë„ì–´ì“°ê¸° / ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ / ë‹¨ìˆœ ìŠ¤í ë§ ì˜¤ë¥˜**ì—ë§Œ ì§‘ì¤‘í•©ë‹ˆë‹¤.
""")


# --- ë””ë²„ê·¸ íƒ­ ---
with tab_debug:
    st.markdown("ì—¬ê¸°ëŠ” ì¶”í›„ì— ë¡œê·¸, ë””ë²„ê·¸ìš© ì •ë³´ë¥¼ ì¶”ê°€ë¡œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” ì˜ì—­ì…ë‹ˆë‹¤.")
