# sheet_review.py
# -*- coding: utf-8 -*-
import json
import time

import streamlit as st
import pandas as pd
import gspread
import google.generativeai as genai
from google.oauth2.service_account import Credentials

# ---------------------------------------------------
# 1. Gemini / Google Sheets í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# ---------------------------------------------------

# Gemini í‚¤ (secretsì—ì„œ ì½ê¸°)
API_KEY = st.secrets.get("GEMINI_API_KEY")
if not API_KEY:
    st.error("GEMINI_API_KEYê°€ secretsì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

genai.configure(api_key=API_KEY)
MODEL_ID = "gemini-2.0-flash-001"
model = genai.GenerativeModel(MODEL_ID)

# ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ (JSON ì „ì²´ë¥¼ secretsì— ë„£ì–´ë‘ )
service_info = json.loads(st.secrets["GCP_SERVICE_ACCOUNT_JSON"])

SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

creds = Credentials.from_service_account_info(service_info, scopes=SCOPES)
gs_client = gspread.authorize(creds)

# ---------------------------------------------------
# 2. ì‹œíŠ¸ ì»¬ëŸ¼ ì´ë¦„ (ë„¤ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ ê·¸ëŒ€ë¡œ)
# ---------------------------------------------------

STATUS_COL = "STATUS"
ORIGINAL_TEXT_COL = "content"
ORIGINAL_MD_COL = "content_markdown"
TRANSLATION_TEXT_COL = "content_translated"
TRANSLATION_MD_COL = "content_markdown_translated"

SUSPICION_SCORE_COL = "SCORE"
CONTENT_TYPO_REPORT_COL = "CONTENT_TYPO_REPORT"
TRANSLATED_COL = "TRANSLATED_TYPO_REPORT"
MARKDOWN_REPORT_COL = "MARKDOWN_REPORT"


# ---------------------------------------------------
# 3. í”„ë¡¬í”„íŠ¸ / ëª¨ë¸ í˜¸ì¶œ / ê²°ê³¼ ì •ì œ
# ---------------------------------------------------

def create_review_prompt(row: dict) -> str:
    original_text = row.get(ORIGINAL_TEXT_COL, "")
    original_md = row.get(ORIGINAL_MD_COL, "")
    translation_text = row.get(TRANSLATION_TEXT_COL, "")
    translation_md = row.get(TRANSLATION_MD_COL, "")

    prompt = f"""
    You are a machine-like **Data Verifier**. Your ONLY job is to find **objective, factual errors** 
    in both the English source text and the Korean translated text. 
    You are strictly forbidden from judging style, meaning, or making subjective suggestions. 
    Your output MUST BE a single, valid JSON object.

    Your JSON MUST have exactly the following keys:
    - "suspicion_score": an integer between 1 and 5 (1 = almost certainly no error, 5 = very likely serious errors)
    - "content_typo_report": a string (may be empty "")
    - "translated_typo_report": a string (may be empty "")
    - "markdown_report": a string (may be empty "")

    Use the fields as follows:
    - **content_typo_report**: objective errors in the **English source text** (plain_english / markdown_english).
    - **translated_typo_report**: objective errors in the **Korean translated text** (plain_korean / markdown_korean).
    - **markdown_report**: pure **markdown vs plain-text mismatches** (missing words, extra words, broken formatting) 
      for either English or Korean.

    ---

    ## 1. What counts as an objective error?

    You must ONLY report the following error types.

    ### 1-A. For English (plain_english / markdown_english)

    1. **Spelling / Typos (VERY IMPORTANT)**
       - Any obviously misspelled English word MUST be treated as an error,
         not only specific examples.
       - Treat a token as a spelling typo if:
         - It is very similar to a common English word (1â€“2 letters missing, added, swapped, or wrong),
           AND
         - It is not clearly a proper noun, acronym, variable name, or chemical formula.
       - Examples (these are patterns, NOT an exhaustive list):
         - "recieve"  â†’ "receive"
         - "enviroment" â†’ "environment"
         - "understaning" â†’ "understanding"
         - "langauge" â†’ "language"
         - "teh" â†’ "the"
         - "problme" â†’ "problem"

       - Counter-examples (DO NOT mark these as spelling errors):
         - Proper nouns or product names: "OpenAI", "ChatGPT", "PyTorch"
         - Technical tokens / code / formulas: "int64", "Al2O3", "NaCl"

    2. **Obvious spacing / duplication errors**
       - Accidental extra spaces inside a word, or duplicated words.
       - Examples:
         - "re turn" â†’ "return"
         - "the the" â†’ "the"

       3. **AI vs Al typo in AI-related context**
       - In contexts clearly about artificial intelligence (e.g. "model", "system", "tool",
         "chatbot", "LLM", "agent", "neural network"), the token "Al"
         (capital A + lowercase L) is almost always a typo for "AI".
       - In such contexts, you MUST treat "Al" as a spelling error and correct it to "AI".
       - Examples:
         - "Al model"   â†’ "AI model"
         - "modern Al technology" â†’ "modern AI technology"
         - "Al chatbot" â†’ "AI chatbot"

    4. **Plain vs Markdown content mismatch (English)**
       - A word or phrase is missing in markdown, duplicated, or obviously wrong compared to the plain version.
       - Example:
         - plain_english: "He went to school yesterday."
         - markdown_english: "He went school yesterday."
         â†’ Missing "to" is an objective mismatch.

    ### 1-B. For Korean (plain_korean / markdown_korean)

    1.  **Typos (ì˜¤íƒˆì)**  
        - ì˜ëª»ëœ ì² ì, ì¤‘ë³µ ê¸€ì, ëª…ë°±í•œ ì…ë ¥ ì‹¤ìˆ˜  
        - ì˜ˆ: "ì´ì ë“¤ì„ë¥¼" â†’ "ì´ì ë“¤ì„"

    2.  **Grammatical Errors (ì¡°ì‚¬, ì–´ë¯¸)**  
        - ì£¼ê²©/ëª©ì ê²©/ë³´ê²©/ë¶€ì‚¬ê²© ì¡°ì‚¬ ì˜ëª» ì‚¬ìš©  
        - ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ë¯¸ê°€ ë¬¸ë²•ì ìœ¼ë¡œ ë¶„ëª…íˆ ì˜ëª»ëœ ê²½ìš°  
        - ì˜ˆ: "ì‚¬ê³¼ì„" â†’ "ì‚¬ê³¼ë¥¼"

    3.  **Spacing (ë„ì–´ì“°ê¸°) errors**  
        - ë„ì–´ì“°ê¸°/ë¶™ì—¬ì“°ê¸° ê·œë²”ì´ ëª…ë°±íˆ ì˜ëª»ëœ ê²½ìš°  
        - ì˜ˆ: "ì±…ì„ì½ê³ " â†’ "ì±…ì„ ì½ê³ "

    4.  **Basic punctuation (ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸) errors**  
        - ë§ˆì¹¨í‘œ/ì‰¼í‘œ/ë¬¼ìŒí‘œ ë“± í•„ìˆ˜ ë¬¸ì¥ë¶€í˜¸ê°€ ë¹ ì ¸
          ë¬¸ì¥ì´ ë¹„ë¬¸ì´ ë˜ê±°ë‚˜ êµ¬ì¡°ê°€ ì‹¬ê°í•˜ê²Œ ëª¨í˜¸í•œ ê²½ìš°.
        - ë”°ì˜´í‘œ/ìŒë”°ì˜´í‘œê°€ í•œìª½ë§Œ ìˆê±°ë‚˜ ì§ì´ ì•ˆ ë§ëŠ” ê²½ìš°ëŠ” **í•­ìƒ ì˜¤ë¥˜**ì´ë‹¤.
        - ë¬¸ë‹¨ ì²« ë²ˆì§¸ ë¬¸ì¥ì—ì„œëŠ” ë¬¸ì¥ ë¶€í˜¸ ëˆ„ë½ ì—¬ë¶€ë¥¼ íŠ¹íˆ ì£¼ì˜í•´ì„œ í™•ì¸í•œë‹¤.
        - ì˜ˆ:
          - ì˜ëª»ëœ ì˜ˆ: ë‚˜ëŠ” ë§í•œë‹¤."
          - ì˜¬ë°”ë¥¸ ì˜ˆ: "ë‚˜ëŠ” ë§í•œë‹¤."

    5.  **Morpheme Split Errors (í˜•íƒœì†Œ ë¶„ë¦¬ ì˜¤ë¥˜)**  
        - ë™ì‚¬, í˜•ìš©ì‚¬, ì–´ë¯¸, ì¡°ì‚¬ ë“± í•˜ë‚˜ì˜ í˜•íƒœì†Œë¡œ ê²°í•©ë˜ì–´ì•¼ í•˜ëŠ” í•­ëª©ì´ 
          ë¶€ì ì ˆí•˜ê²Œ ë¶„ë¦¬ëœ ê²½ìš°ëŠ” **ë¬´ì¡°ê±´ ì˜¤ë¥˜**ë¡œ íŒë‹¨í•œë‹¤. 
        - ì˜ˆ:
          - "ë¬» ëŠ”" â†’ "ë¬»ëŠ”"
          - "ë¨¹ ëŠ”" â†’ "ë¨¹ëŠ”"
          - "ì¡ ì•„" â†’ "ì¡ì•„"
          - "ëœ ë‹¤" â†’ "ëœë‹¤"
          - "ê°„ ë‹¤" â†’ "ê°„ë‹¤"
        - ë‹¨, í•œêµ­ì–´ ë§ì¶¤ë²•ì—ì„œ ë‘ í˜•íƒœ ëª¨ë‘ í—ˆìš©ë˜ëŠ” ë„ì–´ì“°ê¸°(ì˜ˆ: "í•´ ë³´ë‹¤"/"í•´ë³´ë‹¤")ëŠ” ì œì™¸í•œë‹¤.

    6.  **Repetition Typos (ë°˜ë³µ ì˜¤íƒ€)**  
        - ìœ íš¨í•œ í•œêµ­ì–´ ë‹¨ì–´ë¥¼ ì´ë£¨ì§€ ëª»í•˜ëŠ” ìŒì ˆ/ê¸€ì ë°˜ë³µì€ **í•­ìƒ ì˜¤íƒ€**ë¡œ íŒë‹¨í•œë‹¤.
        - ì˜ˆ:
          - "ëœë‹¤ë”°ë”°." â†’ "ëœë‹¤."
          - "í•©ë‹ˆë‹¤ì•„ì•„" â†’ "í•©ë‹ˆë‹¤."
          - "ê°„ë‹¤ë‹¤ë‹¤" â†’ "ê°„ë‹¤."

    7.  **Plain vs Markdown content mismatch (Korean)**  
        - plain_koreanê³¼ markdown_korean ì‚¬ì´ì— ë‹¨ì–´ê°€ ë¹ ì§€ê±°ë‚˜, ì˜ëª» ì¶”ê°€ë˜ê±°ë‚˜, 
          ëª…ë°±íˆ ë‹¤ë¥¸ ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ë³´ê³ í•œë‹¤.

    ---

    ## 2. CRITICAL RULES OF ENGAGEMENT (for BOTH English and Korean)

    1.  **ABSOLUTELY NO STYLISTIC FEEDBACK:** 
        Do NOT suggest alternative wording (e.g., "ê·¼ì‚¬í•œ" vs "ë©‹ìˆëŠ”", 
        "big" vs "large"). Do not comment on what sounds "more natural" or "more appropriate". 
        This is a critical failure.

    2.  **SILENCE ON PERFECTION:** 
        If no objective errors are found for a given field, its report MUST be an empty string (`""`). 
        Do not write phrases like "ì˜¤ë¥˜ ì—†ìŒ", "ë¬¸ì œ ì—†ìŒ", "ì •ìƒ", "no issues", etc.

    3.  **RESPECT STYLING CONVENTIONS:** 
        It is CORRECT for *italicized English* to be represented with 'single quotes' or ã€Šdouble angle bracketsã€‹ 
        in Korean. This is NOT an error.

    4.  **GROUND YOUR FINDINGS:** 
        When reporting an error, you MUST quote the problematic text and provide the corrected form.

    5.  **NO IDENTICAL CORRECTIONS:** 
        A suggested correction must be different from the original text.

    ---

    ## 3. EXAMPLES OF CORRECT EXECUTION

    **Example: English typo**
    - plain_english: "We can easily understaning the data."
    - Correct JSON (excerpt):
    {{
        "content_typo_report": "- 'understaning' is a spelling mistake. It must be 'understanding'.",
        ...
    }}

    **Example: AI vs Al typo**
    - plain_english: "Our Al model learns from data."
    - Correct JSON (excerpt):
    {{
        "content_typo_report": "- In 'Al model', 'Al' is a typo in an AI context. It must be 'AI model'.",
        ...
    }}

    **Example: Korean repetition typo**
    - plain_korean: "ëœë‹¤ë”°ë”°."
    - Correct JSON (excerpt):
    {{
        "translated_typo_report": "- 'ëœë‹¤ë”°ë”°.'ì—ì„œ ë¶ˆí•„ìš”í•œ ë°˜ë³µ 'ë”°ë”°'ê°€ ìˆìŒ. 'ëœë‹¤.'ë¡œ ìˆ˜ì •í•´ì•¼ í•¨.",
        ...
    }}

    **Example: Korean morpheme split**
    - plain_korean: "ê·¸ë ‡ê²Œ ëœ ë‹¤."
    - Correct JSON (excerpt):
    {{
        "translated_typo_report": "- 'ëœ ë‹¤'ì—ì„œ í˜•íƒœì†Œ ë¶„ë¦¬ ì˜¤ë¥˜. 'ëœë‹¤'ë¡œ ë¶™ì—¬ ì¨ì•¼ í•¨.",
        ...
    }}

    **Example: Unbalanced quotes**
    - plain_korean: ë‚˜ëŠ” ë§í•œë‹¤."
    - Correct JSON (excerpt):
    {{
        "translated_typo_report": "- ë”°ì˜´í‘œê°€ í•œìª½ë§Œ ìˆìŒ. '\"ë‚˜ëŠ” ë§í•œë‹¤.\"'ì²˜ëŸ¼ ì‹œì‘ê³¼ ëì„ ëª¨ë‘ ì¨ì•¼ í•¨.",
        ...
    }}

    ---

    ## 4. ANALYSIS WORKFLOW

    Now, apply these strict rules and examples to the following data.

    **Data to Review:**
    - `plain_english`: "{original_text}"
    - `markdown_english`: "{original_md}"
    - `plain_korean`: "{translation_text}"
    - `markdown_korean`: "{translation_md}"
    """
    return prompt


def analyze_text_with_gemini(prompt: str, max_retries: int = 5) -> dict:
    for attempt in range(max_retries):
        try:
            generation_config = {
                "response_mime_type": "application/json",
                "temperature": 0.0,
            }
            response = model.generate_content(prompt, generation_config=generation_config)
            return json.loads(response.text)
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 5 * (attempt + 1)
                print(f"Gemini í˜¸ì¶œ ì˜¤ë¥˜ (ì‹œë„ {attempt+1}/{max_retries}): {e} â†’ {wait_time}ì´ˆ í›„ ì¬ì‹œë„")
                time.sleep(wait_time)
            else:
                print("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼.")
                return {
                    "suspicion_score": 5,
                    "content_typo_report": f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}",
                    "translated_typo_report": "",
                    "markdown_report": "",
                }


def validate_and_clean_analysis(result: dict) -> dict:
    if not isinstance(result, dict):
        return {
            "suspicion_score": 5,
            "content_typo_report": "AI ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹˜",
            "translated_typo_report": "",
            "markdown_report": "",
        }

    score = result.get("suspicion_score")
    reports = {
        "content_typo_report": result.get("content_typo_report", ""),
        "translated_typo_report": result.get("translated_typo_report", ""),
        "markdown_report": result.get("markdown_report", ""),
    }

    forbidden_keywords = [
        "ë¬¸ë§¥ìƒ",
        "ë¶€ì ì ˆ",
        "ì–´ìƒ‰",
        "ë” ìì—°ìŠ¤ëŸ½",
        "ë” ì ì ˆ",
        "ìˆ˜ì •í•˜ëŠ” ê²ƒì´ ì¢‹",
        "ì œì•ˆ",
        "ë°”ê¾¸ëŠ” ê²ƒ",
        "ì˜ë¯¸ë¥¼ ëª…í™•íˆ",
    ]
    for key, text in reports.items():
        if any(kw in text for kw in forbidden_keywords):
            reports[key] = ""

    forbidden_phrases = ["ì˜¤ë¥˜ ì—†ìŒ", "ì •ìƒ", "ë¬¸ì œ ì—†ìŒ", "ìˆ˜ì •í•  í•„ìš” ì—†ìŒ"]
    for key, text in reports.items():
        if any(ph in text for ph in forbidden_phrases):
            reports[key] = ""

    final_content = reports["content_typo_report"]
    final_translated = reports["translated_typo_report"]
    final_markdown = reports["markdown_report"]

    if not final_content and not final_translated and not final_markdown:
        score = 1
    elif (final_content or final_translated or final_markdown) and score == 1:
        score = 3

    return {
        "suspicion_score": score,
        "content_typo_report": final_content,
        "translated_typo_report": final_translated,
        "markdown_report": final_markdown,
    }


# ---------------------------------------------------
# 4. ê³µê°œ í•¨ìˆ˜: ì‹œíŠ¸ ì „ì²´ë¥¼ ëŒë¦¬ê³  ìš”ì•½ ë¦¬í„´
# ---------------------------------------------------

def run_sheet_review(spreadsheet_name: str,
                     worksheet_name: str,
                     collect_raw: bool = False, 
                     progress_callback=None,) -> dict:
    """
    - ì£¼ì–´ì§„ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ / ì›Œí¬ì‹œíŠ¸ì—ì„œ
    - STATUS == '1. AIê²€ìˆ˜ìš”ì²­' ì¸ í–‰ë§Œ ê³¨ë¼ì„œ
    - SCORE / *_REPORT / STATUSë¥¼ ì±„ì›Œë„£ëŠ”ë‹¤.

    ë°˜í™˜ê°’: {
      "total_rows": ...,
      "target_rows": ...,
      "processed_rows": ...,
      "raw_results": [  # collect_raw=Trueì¼ ë•Œë§Œ
          {
            "sheet_row_index": int,
            "raw": {...},      # validate ì „ ì›ë³¸ JSON
            "final": {...},    # validate_and_clean_analysis ì´í›„
          },
          ...
      ]
    }
    """
    try:
        spreadsheet = gs_client.open(spreadsheet_name)
    except gspread.exceptions.SpreadsheetNotFound:
        raise ValueError(f"ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {spreadsheet_name}")

    try:
        worksheet = spreadsheet.worksheet(worksheet_name)
    except gspread.exceptions.WorksheetNotFound:
        raise ValueError(f"ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {worksheet_name}")

    all_data = worksheet.get_all_records()
    df = pd.DataFrame(all_data)
    df["sheet_row_index"] = df.index + 2  # 1í–‰ì€ í—¤ë”ë¼ì„œ +2

    targets = df[df[STATUS_COL] == "1. AIê²€ìˆ˜ìš”ì²­"].copy()
    if targets.empty:
        return {
            "total_rows": len(df),
            "target_rows": 0,
            "processed_rows": 0,
            "raw_results": [],
        }

    results = []
    raw_results = []  # ğŸ”¹ ë””ë²„ê·¸ìš©

    total_targets = len(targets)


    for i, (_, row) in enumerate(targets.iterrows(), start=1):
        row_dict = row.to_dict()
        row_idx = row["sheet_row_index"]
        print(f"í–‰ {row_idx} ê²€ìˆ˜ ì¤‘... ({i}/{total_targets})")
        
        if progress_callback is not None:
            # progress_callback(ì²˜ë¦¬í•œ ê°œìˆ˜, ì „ì²´ ê°œìˆ˜)
            progress_callback(i, total_targets)

        prompt = create_review_prompt(row_dict)
        raw = analyze_text_with_gemini(prompt)
        final = validate_and_clean_analysis(raw)

        results.append(
            {
                "sheet_row_index": row_idx,
                SUSPICION_SCORE_COL: final.get("suspicion_score"),
                CONTENT_TYPO_REPORT_COL: final.get("content_typo_report"),
                TRANSLATED_COL: final.get("translated_typo_report"),
                MARKDOWN_REPORT_COL: final.get("markdown_report"),
                STATUS_COL: "2. AIê²€ìˆ˜ì™„ë£Œ",
            }
        )
        
         # ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ë³¼ raw ë””ë²„ê·¸ìš©
        if collect_raw:
            raw_results.append(
                {
                    "sheet_row_index": row_idx,
                    "raw": raw,
                    "final": final,
                }
            )

        time.sleep(0.5)  # API ê³¼ë‹¤ í˜¸ì¶œ ë°©ì§€ìš© (í•„ìš”ì‹œ ì¡°ì •)

    # === ì‹œíŠ¸ì— ê²°ê³¼ ë°˜ì˜ ===
    headers = worksheet.row_values(1)
    score_col_idx = headers.index(SUSPICION_SCORE_COL) + 1
    content_col_idx = headers.index(CONTENT_TYPO_REPORT_COL) + 1
    translated_col_idx = headers.index(TRANSLATED_COL) + 1
    markdown_col_idx = headers.index(MARKDOWN_REPORT_COL) + 1
    status_col_idx = headers.index(STATUS_COL) + 1

    def sanitize(v):
        return "" if v is None else str(v)

    update_cells = []
    for r in results:
        ridx = r["sheet_row_index"]
        update_cells.append(gspread.Cell(ridx, score_col_idx, sanitize(r[SUSPICION_SCORE_COL])))
        update_cells.append(gspread.Cell(ridx, content_col_idx, sanitize(r[CONTENT_TYPO_REPORT_COL])))
        update_cells.append(gspread.Cell(ridx, translated_col_idx, sanitize(r[TRANSLATED_COL])))
        update_cells.append(gspread.Cell(ridx, markdown_col_idx, sanitize(r[MARKDOWN_REPORT_COL])))
        update_cells.append(gspread.Cell(ridx, status_col_idx, sanitize(r[STATUS_COL])))

    if update_cells:
        worksheet.update_cells(update_cells)

    return {
        "total_rows": len(df),
        "target_rows": len(targets),
        "processed_rows": len(results),
        "raw_results": raw_results,   # ğŸ”¹ ì—¬ê¸° ì¶”ê°€

    }
